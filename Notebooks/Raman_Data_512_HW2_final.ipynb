{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raman SV - Data 512 - Assignment 2\n",
    "\n",
    "Snippets of code in this document are either used as is or modified based on the example code shared by Dr. David McDonald, professor for Data 512\n",
    "\n",
    "These are from the notebooks - \"wp_page_info_example\" and \"wp_ores_liftwing_example\" shared as part of the starter code for this assignment\n",
    "\n",
    "These are licensed CC-BY (https://creativecommons.org/licenses/by/4.0/) by the original author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This entire notebook along with the datasources are licensed CC-BY (https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import  the necessary libraries and packages for this project and setup the local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, time, urllib.parse\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "Curr_Dir = 'C:/Users/raman/OneDrive/Desktop/UDubs/Classroom/Q4/Data 512 - HCDE/Assignments/Week 2/data-512-homework_2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below 2 files contain the region and divisions for the US states and the population estimates for 2022.\n",
    "The population estimates are obtained from this link [State Population Totals and Components of Change: 2020-2022](https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html)\n",
    "\n",
    "These 2 files are merged to get a list of states, their Regional Division and 2022 estimated population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>regional_division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>West (Pacific)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>West</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>West (Mountain)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>South (West South Central)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>West (Pacific)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REGION            DIVISION       STATE            regional_division\n",
       "0  South  East South Central     Alabama  South (East South Central) \n",
       "1   West             Pacific      Alaska              West (Pacific) \n",
       "2   West            Mountain     Arizona             West (Mountain) \n",
       "3  South  West South Central    Arkansas  South (West South Central) \n",
       "4   West             Pacific  California              West (Pacific) "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_by_region = pd.read_excel(os.path.join(Curr_Dir,'Input Files', 'US States by Region - US Census Bureau.xlsx'))\n",
    "\n",
    "states_by_region['regional_division'] = states_by_region['REGION'] + ' (' + states_by_region['DIVISION'] + ') '\n",
    "\n",
    "#print(states_by_region.columns)\n",
    "states_by_region.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geographic Area</th>\n",
       "      <th>April 1, 2020 Estimates Base</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>331449520</td>\n",
       "      <td>333287557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Northeast</td>\n",
       "      <td>57609156</td>\n",
       "      <td>57040406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Midwest</td>\n",
       "      <td>68985537</td>\n",
       "      <td>68787595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South</td>\n",
       "      <td>126266262</td>\n",
       "      <td>128716192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>West</td>\n",
       "      <td>78588565</td>\n",
       "      <td>78743364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5024356</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>733378</td>\n",
       "      <td>733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7151507</td>\n",
       "      <td>7359197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3011555</td>\n",
       "      <td>3045637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California</td>\n",
       "      <td>39538245</td>\n",
       "      <td>39029342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Geographic Area  April 1, 2020 Estimates Base       2022\n",
       "0   United States                     331449520  333287557\n",
       "1       Northeast                      57609156   57040406\n",
       "2         Midwest                      68985537   68787595\n",
       "3           South                     126266262  128716192\n",
       "4            West                      78588565   78743364\n",
       "5         Alabama                       5024356    5074296\n",
       "6          Alaska                        733378     733583\n",
       "7         Arizona                       7151507    7359197\n",
       "8        Arkansas                       3011555    3045637\n",
       "9      California                      39538245   39029342"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_2022_est = pd.read_excel(os.path.join(Curr_Dir,'Input Files', 'NST-EST2022-POP.xlsx'))\n",
    "#print(population_2022_est.columns)\n",
    "population_2022_est.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>regional_division</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>West (Pacific)</td>\n",
       "      <td>733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>West (Mountain)</td>\n",
       "      <td>7359197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>South (West South Central)</td>\n",
       "      <td>3045637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>West (Pacific)</td>\n",
       "      <td>39029342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATE            regional_division  Population Est. 2022\n",
       "0     Alabama  South (East South Central)                5074296\n",
       "1      Alaska              West (Pacific)                 733583\n",
       "2     Arizona             West (Mountain)                7359197\n",
       "3    Arkansas  South (West South Central)                3045637\n",
       "4  California              West (Pacific)               39029342"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_by_region_with_pop = pd.merge(states_by_region[['STATE', 'regional_division']], population_2022_est[['Geographic Area', 2022]], left_on='STATE', right_on='Geographic Area', how= 'left' )\n",
    "states_by_region_with_pop.drop(columns=['Geographic Area'], inplace=True)\n",
    "states_by_region_with_pop.rename(columns={2022: 'Population Est. 2022'}, inplace=True)\n",
    "\n",
    "states_by_region_with_pop.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the list of cities by states that will act as the source. Source file courtesy of Dr. David McDonald, professor for Data 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abbeville,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adamsville,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Addison,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Akron,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alabaster,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Courtland, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Courtland,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cowarts, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cowarts,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Creola, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Creola,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Crossville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Crossville,_Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cuba, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cuba,_Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state           page_title  \\\n",
       "0   Alabama   Abbeville, Alabama   \n",
       "1   Alabama  Adamsville, Alabama   \n",
       "2   Alabama     Addison, Alabama   \n",
       "3   Alabama       Akron, Alabama   \n",
       "4   Alabama   Alabaster, Alabama   \n",
       "..      ...                  ...   \n",
       "95  Alabama   Courtland, Alabama   \n",
       "96  Alabama     Cowarts, Alabama   \n",
       "97  Alabama      Creola, Alabama   \n",
       "98  Alabama  Crossville, Alabama   \n",
       "99  Alabama        Cuba, Alabama   \n",
       "\n",
       "                                                  url  \n",
       "0    https://en.wikipedia.org/wiki/Abbeville,_Alabama  \n",
       "1   https://en.wikipedia.org/wiki/Adamsville,_Alabama  \n",
       "2      https://en.wikipedia.org/wiki/Addison,_Alabama  \n",
       "3        https://en.wikipedia.org/wiki/Akron,_Alabama  \n",
       "4    https://en.wikipedia.org/wiki/Alabaster,_Alabama  \n",
       "..                                                ...  \n",
       "95   https://en.wikipedia.org/wiki/Courtland,_Alabama  \n",
       "96     https://en.wikipedia.org/wiki/Cowarts,_Alabama  \n",
       "97      https://en.wikipedia.org/wiki/Creola,_Alabama  \n",
       "98  https://en.wikipedia.org/wiki/Crossville,_Alabama  \n",
       "99        https://en.wikipedia.org/wiki/Cuba,_Alabama  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list_source = pd.read_csv(os.path.join(Curr_Dir,'Input Files', 'us_cities_by_state_SEPT.2023.csv'))\n",
    "state_list_source.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the above 3 datasets to get a list of states, their regional division, the cities and the population estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>url</th>\n",
       "      <th>regional_division</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abbeville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adamsville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Addison,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Akron,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alabaster,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Courtland, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Courtland,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cowarts, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cowarts,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Creola, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Creola,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Crossville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Crossville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cuba, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cuba,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state           page_title  \\\n",
       "0   Alabama   Abbeville, Alabama   \n",
       "1   Alabama  Adamsville, Alabama   \n",
       "2   Alabama     Addison, Alabama   \n",
       "3   Alabama       Akron, Alabama   \n",
       "4   Alabama   Alabaster, Alabama   \n",
       "..      ...                  ...   \n",
       "95  Alabama   Courtland, Alabama   \n",
       "96  Alabama     Cowarts, Alabama   \n",
       "97  Alabama      Creola, Alabama   \n",
       "98  Alabama  Crossville, Alabama   \n",
       "99  Alabama        Cuba, Alabama   \n",
       "\n",
       "                                                  url  \\\n",
       "0    https://en.wikipedia.org/wiki/Abbeville,_Alabama   \n",
       "1   https://en.wikipedia.org/wiki/Adamsville,_Alabama   \n",
       "2      https://en.wikipedia.org/wiki/Addison,_Alabama   \n",
       "3        https://en.wikipedia.org/wiki/Akron,_Alabama   \n",
       "4    https://en.wikipedia.org/wiki/Alabaster,_Alabama   \n",
       "..                                                ...   \n",
       "95   https://en.wikipedia.org/wiki/Courtland,_Alabama   \n",
       "96     https://en.wikipedia.org/wiki/Cowarts,_Alabama   \n",
       "97      https://en.wikipedia.org/wiki/Creola,_Alabama   \n",
       "98  https://en.wikipedia.org/wiki/Crossville,_Alabama   \n",
       "99        https://en.wikipedia.org/wiki/Cuba,_Alabama   \n",
       "\n",
       "              regional_division  Population Est. 2022  \n",
       "0   South (East South Central)                5074296  \n",
       "1   South (East South Central)                5074296  \n",
       "2   South (East South Central)                5074296  \n",
       "3   South (East South Central)                5074296  \n",
       "4   South (East South Central)                5074296  \n",
       "..                          ...                   ...  \n",
       "95  South (East South Central)                5074296  \n",
       "96  South (East South Central)                5074296  \n",
       "97  South (East South Central)                5074296  \n",
       "98  South (East South Central)                5074296  \n",
       "99  South (East South Central)                5074296  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list = pd.merge(state_list_source, states_by_region_with_pop, left_on='state', right_on='STATE', how= 'left' )\n",
    "state_list.drop(columns=['STATE'], inplace=True)\n",
    "\n",
    "output_excel_path = os.path.join(Curr_Dir, 'Input Files', 'test_temp.xlsx')\n",
    "state_list.to_excel(output_excel_path, index=False)\n",
    "\n",
    "state_list.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pageview Variables initialization\n",
    "The below code (and comments) is mainly derived from the aforementioned starter code for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<svraman@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "# ARTICLE_TITLES = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages. Therefore the parameter most likely to change is the article_title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None,\n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT,\n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>url</th>\n",
       "      <th>regional_division</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abbeville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adamsville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Addison,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Akron,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alabaster,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Albertville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Albertville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alexander City, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alexander_City,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Aliceville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aliceville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Allgood, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Allgood,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Altoona, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Altoona,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state               page_title  \\\n",
       "0  Alabama       Abbeville, Alabama   \n",
       "1  Alabama      Adamsville, Alabama   \n",
       "2  Alabama         Addison, Alabama   \n",
       "3  Alabama           Akron, Alabama   \n",
       "4  Alabama       Alabaster, Alabama   \n",
       "5  Alabama     Albertville, Alabama   \n",
       "6  Alabama  Alexander City, Alabama   \n",
       "7  Alabama      Aliceville, Alabama   \n",
       "8  Alabama         Allgood, Alabama   \n",
       "9  Alabama         Altoona, Alabama   \n",
       "\n",
       "                                                     url  \\\n",
       "0       https://en.wikipedia.org/wiki/Abbeville,_Alabama   \n",
       "1      https://en.wikipedia.org/wiki/Adamsville,_Alabama   \n",
       "2         https://en.wikipedia.org/wiki/Addison,_Alabama   \n",
       "3           https://en.wikipedia.org/wiki/Akron,_Alabama   \n",
       "4       https://en.wikipedia.org/wiki/Alabaster,_Alabama   \n",
       "5     https://en.wikipedia.org/wiki/Albertville,_Alabama   \n",
       "6  https://en.wikipedia.org/wiki/Alexander_City,_Alabama   \n",
       "7      https://en.wikipedia.org/wiki/Aliceville,_Alabama   \n",
       "8         https://en.wikipedia.org/wiki/Allgood,_Alabama   \n",
       "9         https://en.wikipedia.org/wiki/Altoona,_Alabama   \n",
       "\n",
       "             regional_division  Population Est. 2022  \n",
       "0  South (East South Central)                5074296  \n",
       "1  South (East South Central)                5074296  \n",
       "2  South (East South Central)                5074296  \n",
       "3  South (East South Central)                5074296  \n",
       "4  South (East South Central)                5074296  \n",
       "5  South (East South Central)                5074296  \n",
       "6  South (East South Central)                5074296  \n",
       "7  South (East South Central)                5074296  \n",
       "8  South (East South Central)                5074296  \n",
       "9  South (East South Central)                5074296  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code that utilizes the above function to get the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104730': {'pageid': 104730, 'ns': 0, 'title': 'Abbeville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1171163550, 'length': 24706, 'talkid': 281244, 'fullurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Abbeville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104761': {'pageid': 104761, 'ns': 0, 'title': 'Adamsville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1177621427, 'length': 18040, 'talkid': 281272, 'fullurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Adamsville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105188': {'pageid': 105188, 'ns': 0, 'title': 'Addison, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1168359898, 'length': 13309, 'talkid': 281517, 'fullurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Addison,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104726': {'pageid': 104726, 'ns': 0, 'title': 'Akron, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1165909508, 'length': 11710, 'talkid': 281240, 'fullurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Akron,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105109': {'pageid': 105109, 'ns': 0, 'title': 'Alabaster, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179139816, 'length': 20343, 'talkid': 281444, 'fullurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alabaster,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Response\n",
       "0      {'batchcomplete': '', 'query': {'pages': {'104730': {'pageid': 104730, 'ns': 0, 'title': 'Abbeville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1171163550, 'length': 24706, 'talkid': 281244, 'fullurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Abbeville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama'}}}}\n",
       "1  {'batchcomplete': '', 'query': {'pages': {'104761': {'pageid': 104761, 'ns': 0, 'title': 'Adamsville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1177621427, 'length': 18040, 'talkid': 281272, 'fullurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Adamsville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama'}}}}\n",
       "2              {'batchcomplete': '', 'query': {'pages': {'105188': {'pageid': 105188, 'ns': 0, 'title': 'Addison, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1168359898, 'length': 13309, 'talkid': 281517, 'fullurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Addison,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama'}}}}\n",
       "3                      {'batchcomplete': '', 'query': {'pages': {'104726': {'pageid': 104726, 'ns': 0, 'title': 'Akron, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1165909508, 'length': 11710, 'talkid': 281240, 'fullurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Akron,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama'}}}}\n",
       "4      {'batchcomplete': '', 'query': {'pages': {'105109': {'pageid': 105109, 'ns': 0, 'title': 'Alabaster, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179139816, 'length': 20343, 'talkid': 281444, 'fullurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alabaster,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama'}}}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list_data = []\n",
    "\n",
    "for i, title in enumerate(state_list['page_title']):\n",
    "    PageInfo = request_pageinfo_per_article(title)\n",
    "    #print(PageInfo)\n",
    "    # Had to add the below logic as a keyerror for items was being returned for the code, this handles\n",
    "    # scenarios where items is not part of the response for any reason\n",
    "    if PageInfo is not None and isinstance(PageInfo, dict) and 'query' in PageInfo:\n",
    "\n",
    "        # df = pd.DataFrame(PageInfo)\n",
    "        state_list_data.append(PageInfo)\n",
    "\n",
    "    else:\n",
    "        print(\"No valid response\")\n",
    "\n",
    "state_list_data = pd.DataFrame({'Response': state_list_data})\n",
    "\n",
    "\n",
    "output_excel_path = os.path.join(Curr_Dir, 'Intermediate files', 'responses_for_states.xlsx')\n",
    "state_list_data.to_excel(output_excel_path, index=False)\n",
    "\n",
    "# Now, 'df' contains all the responses in a single column\n",
    "state_list_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code took 87 minutes to execute. It would be better to either break this bigger loop into smaller loops of 1000 runs or send 50 requests as an array each to ensure there is no time out or missing out on data due to network or computer issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the lastrevid and related details for the states, we have to define the methodology that will generate the page score.\n",
    "Some of the code in the below segments are from the notebook \"wp_ores_liftwing_example\" shared as part of the starter code for this assignment\n",
    "These are licensed CC-BY (https://creativecommons.org/licenses/by/4.0/) by the original author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "#\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (60.0/5000.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "\n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<svraman@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"svraman@uw.edu\",         # your email address should go here\n",
    "    'access_token'  : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiI4MzViYzBjOGFjYTUzYjRiMmMwODBmNzgxNzBiNDMxOSIsImp0aSI6IjEyMjFkYjJhYjM0NGRkMGUzYTA5MTc4NTE4ZTI1ZThlY2QyYjI4NWM0NGNlZDU0ZTNhZDU5OWI3ZDljYWJkNjU0Nzg3MTYxZTYxN2MzNGE5IiwiaWF0IjoxNjk3MzM4MjAwLjc0MTgyMSwibmJmIjoxNjk3MzM4MjAwLjc0MTgyNCwiZXhwIjozMzI1NDI0NzAwMC43Mzk0NzUsInN1YiI6Ijc0MDA2Mzg1IiwiaXNzIjoiaHR0cHM6Ly9tZXRhLndpa2ltZWRpYS5vcmciLCJyYXRlbGltaXQiOnsicmVxdWVzdHNfcGVyX3VuaXQiOjUwMDAsInVuaXQiOiJIT1VSIn0sInNjb3BlcyI6WyJiYXNpYyJdfQ.kEN-6Dwj8qTMdl8oGGsTMSpK9Q-Ics0Ylw33-MhwOOoTJgSX6qGgp71wmDNzKYBkD72ExdbWujX289ZTL-IFiQDiPmIy_lPgguf4DD4yFqP1cOxHqyROW4hI6Rm6YZgMyNbLTuUazqDOqvhH-VQNf2lTbkkYjWOcbF9xDxBOXRcCiknPbH3p1uo_Q20E4_eZv7t-uqjtszhzkOiI3xR6gO9QNDxyYQGtdMM1mfBoj-FlpQ5eYVs-opqS1NSC1SxjtaZZR4ClGut33FjyRkBp92HpTqH-BXXHeXRHcwB4EXBj_rXT72Qv-dIzWR6gocoVGIEjZYTVRLUH4wE15t_sMpiV5CEGIZ3ubk65M5JuW6APT868a0U87Z5VAQvzpgixEGv_qRSP15V5EgpWDatiH1EucUC9tkmRi2nOKI0CKQW8GSdfJa144cekpOOfaLyEIJUhYWcxQWmPElwzUp6_pUy1CHm40ysOa8jRF9HdPMtgV0x_2OprduHDsIHT7RC40qsYNpUhE6Tgx4XazCEjPkCnSKv4l8RajG_dQqMFbA1AiyOwUSKpZkJObWt579DfxK15hqSBuCgzGH3GnfdE8h-qxL_mPOOWtg97Fg-gFxQngyNoeCCpkInei_U9QnY56Ya2DgZkfVNDzFvYXn6Eu3FeXU1T2Bfxp0V7lWL94Gw\"\n",
    "# the access token you create will need to go here\n",
    "}\n",
    "\n",
    "\n",
    "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "#\n",
    "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the API calls, you would need access tokens from Wikimedia. The process for the same is listed below.\n",
    "\n",
    "Once the tokens are obtained, please enter the same in the below code snippet. The below text is from the starter code:\n",
    "\n",
    "\n",
    "    You will need a Wikimedia user account to get access to Lift Wing (the ML API service). You can either [create an account or login](https://api.wikimedia.org/w/index.php?title=Special:UserLogin). If you have a Wikipedia user account - you might already have an Wikimedia account. If you are not sure try your Wikipedia username and password to check it. If you do not have a Wikimedia account you will need to create an account that you can use to get an access token.\n",
    "\n",
    "    There is [a 'guide' that describes how to get authentication tokens](https://api.wikimedia.org/wiki/Authentication) - but not everything works the way it is described in that documentation. You should review that documentation and then read the rest of this comment.\n",
    "\n",
    "    The documentation talks about using a \"dashboard\" for managing authentication tokens. That's a rather generous description for what looks like a simple list of token things. You might have a hard time finding this \"dashboard\". First, on the left hand side of the page, you'll see a column of links. The bottom section is a set of links titled \"Tools\". In that section is a link that says [Special pages](https://api.wikimedia.org/wiki/Special:SpecialPages) which will take you to a list of ... well, special pages. At the very bottom of the \"Special pages\" page is a section titled \"Other special pages\" (scroll all the way to the bottom). The first link in that section is called [API keys](https://api.wikimedia.org/wiki/Special:AppManagement). When you get to the \"API keys\" page you can create a new key.\n",
    "\n",
    "    The authentication guide suggests that you should create a server-side app key. This does not seem to work correctly - as yet. It failed on multiple attempts when I attempted to create a server-side app key. BUT, there is an option to create a [Personal API token](https://api.wikimedia.org/wiki/Authentication) that should work for this course and the type of ORES page scoring that you will need to perform.\n",
    "\n",
    "    Note, when you create a Personal API token you are granted the three items - a Client ID, a Client secret, and a Access token - you shold save all three of these. When you dismiss the box they are gone. If you lose any one of the tokens you can destroy or deactivate the Personal API token from the dashboard and then create a new one.\n",
    "\n",
    "    The value you need to work the code below is the Access token - a very long string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    These are used later - defined here so they, at least, have empty values\n",
    "#\n",
    "USERNAME = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below text and code are from the starter code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define a function to make the ORES API request\n",
    "\n",
    "    The API request will be made using a function to encapsulate call and make access reusable in other notebooks. The procedure is parameterized, relying on the constants above for some important default parameters. The primary assumption is that this function will be used to request data for a set of article revisions. The main parameter is 'article_revid'. One should be able to simply pass in a new article revision id on each call and get back a python dictionary as the result. A valid result will be a dictionary that contains the probabilities that the specific revision is one of six different article quality levels. Generally, quality level with the highest probability score is considered the quality level for the article. This can be tricky when you have two (or more) highly probable quality levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT,\n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL,\n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE,\n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE,\n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "\n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "\n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "\n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "\n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a backup to ensure progress isn't lost\n",
    "#state_list_data.head(5)\n",
    "state_list_data_2 = state_list_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104730': {'pageid': 104730, 'ns': 0, 'title': 'Abbeville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1171163550, 'length': 24706, 'talkid': 281244, 'fullurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Abbeville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104761': {'pageid': 104761, 'ns': 0, 'title': 'Adamsville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1177621427, 'length': 18040, 'talkid': 281272, 'fullurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Adamsville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105188': {'pageid': 105188, 'ns': 0, 'title': 'Addison, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1168359898, 'length': 13309, 'talkid': 281517, 'fullurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Addison,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104726': {'pageid': 104726, 'ns': 0, 'title': 'Akron, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1165909508, 'length': 11710, 'talkid': 281240, 'fullurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Akron,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105109': {'pageid': 105109, 'ns': 0, 'title': 'Alabaster, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179139816, 'length': 20343, 'talkid': 281444, 'fullurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alabaster,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama'}}}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Response\n",
       "0      {'batchcomplete': '', 'query': {'pages': {'104730': {'pageid': 104730, 'ns': 0, 'title': 'Abbeville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1171163550, 'length': 24706, 'talkid': 281244, 'fullurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Abbeville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama'}}}}\n",
       "1  {'batchcomplete': '', 'query': {'pages': {'104761': {'pageid': 104761, 'ns': 0, 'title': 'Adamsville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1177621427, 'length': 18040, 'talkid': 281272, 'fullurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Adamsville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama'}}}}\n",
       "2              {'batchcomplete': '', 'query': {'pages': {'105188': {'pageid': 105188, 'ns': 0, 'title': 'Addison, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1168359898, 'length': 13309, 'talkid': 281517, 'fullurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Addison,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama'}}}}\n",
       "3                      {'batchcomplete': '', 'query': {'pages': {'104726': {'pageid': 104726, 'ns': 0, 'title': 'Akron, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1165909508, 'length': 11710, 'talkid': 281240, 'fullurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Akron,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama'}}}}\n",
       "4      {'batchcomplete': '', 'query': {'pages': {'105109': {'pageid': 105109, 'ns': 0, 'title': 'Alabaster, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179139816, 'length': 20343, 'talkid': 281444, 'fullurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alabaster,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama'}}}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the function is defined, we can call the function by copying and initializing parameter templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>response</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>1171163550</td>\n",
       "      <td>{'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1171163550': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.31042252456158204, 'C': 0.5979200965294227, 'FA': 0.025186220917133947, 'GA': 0.04952133645299354, 'Start': 0.013573873336789355, 'Stub': 0.0033759482020785892}}}}}}}</td>\n",
       "      <td>C</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>1177621427</td>\n",
       "      <td>{'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1177621427': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.198274200391586, 'C': 0.3770695177348356, 'FA': 0.019070364455845708, 'GA': 0.3514876684327692, 'Start': 0.05026148902798659, 'Stub': 0.003836759956977147}}}}}}}</td>\n",
       "      <td>C</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>1168359898</td>\n",
       "      <td>{'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1168359898': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.27104076563661905, 'C': 0.324459707767518, 'FA': 0.011265514086494389, 'GA': 0.29487067754320384, 'Start': 0.0931882446366844, 'Stub': 0.005175090329480344}}}}}}}</td>\n",
       "      <td>C</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>1165909508</td>\n",
       "      <td>{'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1165909508': {'articlequality': {'score': {'prediction': 'GA', 'probability': {'B': 0.175388344565975, 'C': 0.2655870765311225, 'FA': 0.011556876058535826, 'GA': 0.4485841879139288, 'Start': 0.09350806348909406, 'Stub': 0.005375451441343951}}}}}}}</td>\n",
       "      <td>GA</td>\n",
       "      <td>Good article (sometimes called A-class)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>1179139816</td>\n",
       "      <td>{'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1179139816': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.270971932616856, 'C': 0.6463838191722866, 'FA': 0.009590992690925318, 'GA': 0.033641571757281816, 'Start': 0.036340860820955355, 'Stub': 0.003070822941694893}}}}}}}</td>\n",
       "      <td>C</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title   lastrevid  \\\n",
       "0   Abbeville, Alabama  1171163550   \n",
       "1  Adamsville, Alabama  1177621427   \n",
       "2     Addison, Alabama  1168359898   \n",
       "3       Akron, Alabama  1165909508   \n",
       "4   Alabaster, Alabama  1179139816   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                  response  \\\n",
       "0  {'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1171163550': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.31042252456158204, 'C': 0.5979200965294227, 'FA': 0.025186220917133947, 'GA': 0.04952133645299354, 'Start': 0.013573873336789355, 'Stub': 0.0033759482020785892}}}}}}}   \n",
       "1       {'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1177621427': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.198274200391586, 'C': 0.3770695177348356, 'FA': 0.019070364455845708, 'GA': 0.3514876684327692, 'Start': 0.05026148902798659, 'Stub': 0.003836759956977147}}}}}}}   \n",
       "2      {'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1168359898': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.27104076563661905, 'C': 0.324459707767518, 'FA': 0.011265514086494389, 'GA': 0.29487067754320384, 'Start': 0.0931882446366844, 'Stub': 0.005175090329480344}}}}}}}   \n",
       "3      {'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1165909508': {'articlequality': {'score': {'prediction': 'GA', 'probability': {'B': 0.175388344565975, 'C': 0.2655870765311225, 'FA': 0.011556876058535826, 'GA': 0.4485841879139288, 'Start': 0.09350806348909406, 'Stub': 0.005375451441343951}}}}}}}   \n",
       "4    {'enwiki': {'models': {'articlequality': {'version': '0.9.2'}}, 'scores': {'1179139816': {'articlequality': {'score': {'prediction': 'C', 'probability': {'B': 0.270971932616856, 'C': 0.6463838191722866, 'FA': 0.009590992690925318, 'GA': 0.033641571757281816, 'Start': 0.036340860820955355, 'Stub': 0.003070822941694893}}}}}}}   \n",
       "\n",
       "  prediction                          prediction_text  \n",
       "0          C                          C-class article  \n",
       "1          C                          C-class article  \n",
       "2          C                          C-class article  \n",
       "3         GA  Good article (sometimes called A-class)  \n",
       "4          C                          C-class article  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastrevid_values = []\n",
    "title_values = []\n",
    "results = []\n",
    "scores = []\n",
    "# define the parameters to be used in the API call\n",
    "hparams = REQUEST_HEADER_PARAMS_TEMPLATE.copy()\n",
    "rd = ORES_REQUEST_DATA_TEMPLATE.copy()\n",
    "\n",
    "prediction_mapping = {\n",
    "    'FA': 'Featured article',\n",
    "    'GA': 'Good article (sometimes called A-class)',\n",
    "    'B': 'B-class article',\n",
    "    'C': 'C-class article',\n",
    "    'Start': 'Start-class article',\n",
    "    'Stub': 'Stub-class article'\n",
    "}\n",
    "\n",
    "for index, row in state_list_data.iterrows():\n",
    "    response_dict = row['Response']\n",
    "\n",
    "    # Parse values from the response for processing\n",
    "    pages_data = response_dict.get('query', {}).get('pages', {})\n",
    "    lastrevid = None\n",
    "    title = None\n",
    "\n",
    "    for key, page_data in pages_data.items():\n",
    "        lastrevid = page_data.get('lastrevid')\n",
    "        title = page_data.get('title')\n",
    "        if lastrevid:\n",
    "            lastrevid_values.append(lastrevid)\n",
    "            title_values.append(title)\n",
    "            rd['rev_id'] = lastrevid\n",
    "            score = request_ores_score_per_article(request_data=rd, header_params=hparams)\n",
    "            scores.append(score)\n",
    "\n",
    "            prediction = score['enwiki']['scores'].get(str(lastrevid), {}).get('articlequality', {}).get('score', {}).get('prediction')\n",
    "            probability = score['enwiki']['scores'].get(str(lastrevid), {}).get('articlequality', {}).get('score', {}).get('probability', {}).get(prediction, None)\n",
    "            prediction_text = prediction_mapping.get(prediction, None)\n",
    "\n",
    "            result_dict = {\n",
    "                    'title': title,\n",
    "                    'lastrevid': lastrevid,\n",
    "                    'response': score,\n",
    "                    'prediction': prediction,\n",
    "                    'prediction_text': prediction_text\n",
    "                    #'probability': probability\n",
    "            }\n",
    "            results.append(result_dict)\n",
    "\n",
    "            break\n",
    "\n",
    "    if lastrevid is None:\n",
    "        lastrevid_values.append(None)\n",
    "        title_values.append(None)\n",
    "        #scores.append(None)\n",
    "\n",
    "\n",
    "\n",
    "# Add 'lastrevid' values as a new column in the DataFrame\n",
    "#state_list_data['lastrevid'] = lastrevid_values\n",
    "#state_list_data['title'] = title_values\n",
    "#state_list_data['score_response'] = scores\n",
    "results_df = pd.DataFrame(results)\n",
    "#state_list_data = pd.concat([state_list_data, results_df], axis=1)\n",
    "\n",
    "#state_list_data = state_list_data[['title',\t'lastrevid', 'prediction', 'prediction_text','probability']]\n",
    "#state_list_data.head(5)\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Row_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104730': {'pageid': 104730, 'ns': 0, 'title': 'Abbeville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1171163550, 'length': 24706, 'talkid': 281244, 'fullurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Abbeville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama'}}}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104761': {'pageid': 104761, 'ns': 0, 'title': 'Adamsville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1177621427, 'length': 18040, 'talkid': 281272, 'fullurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Adamsville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama'}}}}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105188': {'pageid': 105188, 'ns': 0, 'title': 'Addison, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1168359898, 'length': 13309, 'talkid': 281517, 'fullurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Addison,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama'}}}}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104726': {'pageid': 104726, 'ns': 0, 'title': 'Akron, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1165909508, 'length': 11710, 'talkid': 281240, 'fullurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Akron,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama'}}}}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105109': {'pageid': 105109, 'ns': 0, 'title': 'Alabaster, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179139816, 'length': 20343, 'talkid': 281444, 'fullurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alabaster,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama'}}}}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'104899': {'pageid': 104899, 'ns': 0, 'title': 'Albertville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179198677, 'length': 26930, 'watchers': 34, 'talkid': 281390, 'fullurl': 'https://en.wikipedia.org/wiki/Albertville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Albertville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Albertville,_Alabama'}}}}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105153': {'pageid': 105153, 'ns': 0, 'title': 'Alexander City, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179140073, 'length': 25275, 'watchers': 32, 'talkid': 281484, 'fullurl': 'https://en.wikipedia.org/wiki/Alexander_City,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alexander_City,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alexander_City,_Alabama'}}}}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'105086': {'pageid': 105086, 'ns': 0, 'title': 'Aliceville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1167792390, 'length': 31568, 'talkid': 281424, 'fullurl': 'https://en.wikipedia.org/wiki/Aliceville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Aliceville,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Aliceville,_Alabama'}}}}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'100811': {'pageid': 100811, 'ns': 0, 'title': 'Allgood, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:35Z', 'lastrevid': 1165909718, 'length': 11278, 'talkid': 281031, 'fullurl': 'https://en.wikipedia.org/wiki/Allgood,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Allgood,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Allgood,_Alabama'}}}}</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'batchcomplete': '', 'query': {'pages': {'100812': {'pageid': 100812, 'ns': 0, 'title': 'Altoona, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:35Z', 'lastrevid': 1165909823, 'length': 10679, 'talkid': 281032, 'fullurl': 'https://en.wikipedia.org/wiki/Altoona,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Altoona,_Alabama&amp;action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Altoona,_Alabama'}}}}</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Response  \\\n",
       "0                                      {'batchcomplete': '', 'query': {'pages': {'104730': {'pageid': 104730, 'ns': 0, 'title': 'Abbeville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1171163550, 'length': 24706, 'talkid': 281244, 'fullurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Abbeville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Abbeville,_Alabama'}}}}   \n",
       "1                                  {'batchcomplete': '', 'query': {'pages': {'104761': {'pageid': 104761, 'ns': 0, 'title': 'Adamsville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1177621427, 'length': 18040, 'talkid': 281272, 'fullurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Adamsville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Adamsville,_Alabama'}}}}   \n",
       "2                                              {'batchcomplete': '', 'query': {'pages': {'105188': {'pageid': 105188, 'ns': 0, 'title': 'Addison, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1168359898, 'length': 13309, 'talkid': 281517, 'fullurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Addison,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Addison,_Alabama'}}}}   \n",
       "3                                                      {'batchcomplete': '', 'query': {'pages': {'104726': {'pageid': 104726, 'ns': 0, 'title': 'Akron, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1165909508, 'length': 11710, 'talkid': 281240, 'fullurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Akron,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Akron,_Alabama'}}}}   \n",
       "4                                      {'batchcomplete': '', 'query': {'pages': {'105109': {'pageid': 105109, 'ns': 0, 'title': 'Alabaster, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179139816, 'length': 20343, 'talkid': 281444, 'fullurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alabaster,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alabaster,_Alabama'}}}}   \n",
       "5              {'batchcomplete': '', 'query': {'pages': {'104899': {'pageid': 104899, 'ns': 0, 'title': 'Albertville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179198677, 'length': 26930, 'watchers': 34, 'talkid': 281390, 'fullurl': 'https://en.wikipedia.org/wiki/Albertville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Albertville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Albertville,_Alabama'}}}}   \n",
       "6  {'batchcomplete': '', 'query': {'pages': {'105153': {'pageid': 105153, 'ns': 0, 'title': 'Alexander City, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1179140073, 'length': 25275, 'watchers': 32, 'talkid': 281484, 'fullurl': 'https://en.wikipedia.org/wiki/Alexander_City,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Alexander_City,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Alexander_City,_Alabama'}}}}   \n",
       "7                                  {'batchcomplete': '', 'query': {'pages': {'105086': {'pageid': 105086, 'ns': 0, 'title': 'Aliceville, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:37Z', 'lastrevid': 1167792390, 'length': 31568, 'talkid': 281424, 'fullurl': 'https://en.wikipedia.org/wiki/Aliceville,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Aliceville,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Aliceville,_Alabama'}}}}   \n",
       "8                                              {'batchcomplete': '', 'query': {'pages': {'100811': {'pageid': 100811, 'ns': 0, 'title': 'Allgood, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:35Z', 'lastrevid': 1165909718, 'length': 11278, 'talkid': 281031, 'fullurl': 'https://en.wikipedia.org/wiki/Allgood,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Allgood,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Allgood,_Alabama'}}}}   \n",
       "9                                              {'batchcomplete': '', 'query': {'pages': {'100812': {'pageid': 100812, 'ns': 0, 'title': 'Altoona, Alabama', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'touched': '2023-10-10T22:35:35Z', 'lastrevid': 1165909823, 'length': 10679, 'talkid': 281032, 'fullurl': 'https://en.wikipedia.org/wiki/Altoona,_Alabama', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Altoona,_Alabama&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Altoona,_Alabama'}}}}   \n",
       "\n",
       "   Row_ID  \n",
       "0       1  \n",
       "1       2  \n",
       "2       3  \n",
       "3       4  \n",
       "4       5  \n",
       "5       6  \n",
       "6       7  \n",
       "7       8  \n",
       "8       9  \n",
       "9      10  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a ID column to facilitate processing in chunks\n",
    "state_list_data['Row_ID'] = state_list_data.index + 1\n",
    "state_list_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables\n",
    "lastrevid_values = []\n",
    "title_values = []\n",
    "results = []\n",
    "scores = []\n",
    "\n",
    "hparams = REQUEST_HEADER_PARAMS_TEMPLATE.copy()\n",
    "rd = ORES_REQUEST_DATA_TEMPLATE.copy()\n",
    "\n",
    "prediction_mapping = {\n",
    "    'FA': 'Featured article',\n",
    "    'GA': 'Good article (sometimes called A-class)',\n",
    "    'B': 'B-class article',\n",
    "    'C': 'C-class article',\n",
    "    'Start': 'Start-class article',\n",
    "    'Stub': 'Stub-class article'\n",
    "}\n",
    "\n",
    "# Break for 1-2 minutes, process 750 lines each minute\n",
    "chunk_size = 750\n",
    "break_duration = 60\n",
    "\n",
    "# Create a function to process a chunk of data\n",
    "def process_chunk(chunk):\n",
    "    for index, row in chunk.iterrows():\n",
    "        response_dict = row['Response']\n",
    "\n",
    "        pages_data = response_dict.get('query', {}).get('pages', {})\n",
    "        lastrevid = None\n",
    "        title = None\n",
    "\n",
    "        for key, page_data in pages_data.items():\n",
    "            lastrevid = page_data.get('lastrevid')\n",
    "            title = page_data.get('title')\n",
    "            if lastrevid:\n",
    "                #lastrevid_values.append(lastrevid)\n",
    "                #title_values.append(title)\n",
    "                rd['rev_id'] = lastrevid\n",
    "                score = request_ores_score_per_article(request_data=rd, header_params=hparams)\n",
    "                scores.append(score)\n",
    "\n",
    "                prediction = score['enwiki']['scores'].get(str(lastrevid), {}).get('articlequality', {}).get('score', {}).get('prediction')\n",
    "                probability = score['enwiki']['scores'].get(str(lastrevid), {}).get('articlequality', {}).get('score', {}).get('probability', {}).get(prediction, None)\n",
    "\n",
    "                prediction_text = prediction_mapping.get(prediction, None)\n",
    "\n",
    "                result_dict = {\n",
    "                        'title': title,\n",
    "                        'lastrevid': lastrevid,\n",
    "                        'response': score,\n",
    "                        'prediction': prediction,\n",
    "                        'probability': probability,\n",
    "                        'prediction_text': prediction_text,\n",
    "                        'Row ID': row['Row_ID']\n",
    "                }\n",
    "                results.append(result_dict)\n",
    "\n",
    "                break\n",
    "\n",
    "        if lastrevid is None:\n",
    "            lastrevid_values.append(None)\n",
    "            title_values.append(None)\n",
    "\n",
    "# Process the data in chunks\n",
    "for i in range(18751, max(state_list_data['Row_ID']), chunk_size):\n",
    "    chunk = state_list_data[i:i + chunk_size]\n",
    "    process_chunk(chunk)\n",
    "    output_excel_path = os.path.join(Curr_Dir, 'Intermediate files', 'responses_for_states_' + str(i) + '_' + str(i + chunk_size) + '.xlsx')\n",
    "    temp_results_df = pd.DataFrame(results)\n",
    "\n",
    "    temp_results_df.to_excel(output_excel_path, index=False)\n",
    "    time.sleep(break_duration)  # break for the pre defined amount of time\n",
    "\n",
    "# Create DataFrames\n",
    "results_df = pd.DataFrame(results)\n",
    "#lastrevid_df = pd.DataFrame({'lastrevid': lastrevid_values})\n",
    "#title_df = pd.DataFrame({'title': title_values})\n",
    "\n",
    "# Merge the DataFrames\n",
    "#state_list_data = pd.concat([title_df, lastrevid_df, results_df], axis=1)\n",
    "\n",
    "# Filter columns\n",
    "#state_list_data = state_list_data[['title', 'lastrevid', 'prediction', 'prediction_text']]\n",
    "\n",
    "# Display the first 10 rows of the resulting DataFrame\n",
    "#state_list_data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the results were stored in multiple files to account for batch processing, use the below code to combine the data as a dataframe once all data is processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n",
      "C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_5728\\3633084808.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_df = combined_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title              79156\n",
       "lastrevid          79156\n",
       "response           79156\n",
       "prediction         79156\n",
       "probability        79156\n",
       "prediction_text    79156\n",
       "Row ID             58156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = os.path.join(Curr_Dir, 'Intermediate files', 'All responses')\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        df = pd.read_excel(file_path)\n",
    "        combined_df = combined_df.append(df, ignore_index=True)\n",
    "\n",
    "combined_df.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_excel_path_2 = os.path.join(Curr_Dir, 'Intermediate files', 'responses_for_states_combined' + '.xlsx')\n",
    "combined_df.to_excel(output_excel_path_2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df.head(10)\n",
    "result_processing = combined_df.copy()\n",
    "\n",
    "result_processing.drop(columns=['response'], inplace=True)\n",
    "result_processing.drop(columns=['Row ID'], inplace=True)\n",
    "# 79156 rows\n",
    "result_processing.drop_duplicates(inplace=True)\n",
    "# 21518 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              21518\n",
       "lastrevid          21518\n",
       "prediction         21518\n",
       "probability        21518\n",
       "prediction_text    21518\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result_processing.count()\n",
    "result_processing.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>url</th>\n",
       "      <th>regional_division</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abbeville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adamsville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Addison,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Akron,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alabaster,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Albertville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Albertville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alexander City, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alexander_City,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Aliceville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aliceville,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Allgood, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Allgood,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Altoona, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Altoona,_Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state               page_title  \\\n",
       "0  Alabama       Abbeville, Alabama   \n",
       "1  Alabama      Adamsville, Alabama   \n",
       "2  Alabama         Addison, Alabama   \n",
       "3  Alabama           Akron, Alabama   \n",
       "4  Alabama       Alabaster, Alabama   \n",
       "5  Alabama     Albertville, Alabama   \n",
       "6  Alabama  Alexander City, Alabama   \n",
       "7  Alabama      Aliceville, Alabama   \n",
       "8  Alabama         Allgood, Alabama   \n",
       "9  Alabama         Altoona, Alabama   \n",
       "\n",
       "                                                     url  \\\n",
       "0       https://en.wikipedia.org/wiki/Abbeville,_Alabama   \n",
       "1      https://en.wikipedia.org/wiki/Adamsville,_Alabama   \n",
       "2         https://en.wikipedia.org/wiki/Addison,_Alabama   \n",
       "3           https://en.wikipedia.org/wiki/Akron,_Alabama   \n",
       "4       https://en.wikipedia.org/wiki/Alabaster,_Alabama   \n",
       "5     https://en.wikipedia.org/wiki/Albertville,_Alabama   \n",
       "6  https://en.wikipedia.org/wiki/Alexander_City,_Alabama   \n",
       "7      https://en.wikipedia.org/wiki/Aliceville,_Alabama   \n",
       "8         https://en.wikipedia.org/wiki/Allgood,_Alabama   \n",
       "9         https://en.wikipedia.org/wiki/Altoona,_Alabama   \n",
       "\n",
       "             regional_division  Population Est. 2022  \n",
       "0  South (East South Central)                5074296  \n",
       "1  South (East South Central)                5074296  \n",
       "2  South (East South Central)                5074296  \n",
       "3  South (East South Central)                5074296  \n",
       "4  South (East South Central)                5074296  \n",
       "5  South (East South Central)                5074296  \n",
       "6  South (East South Central)                5074296  \n",
       "7  South (East South Central)                5074296  \n",
       "8  South (East South Central)                5074296  \n",
       "9  South (East South Central)                5074296  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_and_details = pd.merge(state_list[['state','page_title', 'regional_division','Population Est. 2022']], result_processing[['title', 'lastrevid', 'prediction', 'probability', 'prediction_text']], left_on='page_title', right_on='title', how= 'left' )\n",
    "#results_and_details.head(10)\n",
    "\n",
    "results_and_details.drop(columns=['title'], inplace=True)\n",
    "\n",
    "output_excel_path_3 = os.path.join(Curr_Dir, 'Output Files', 'Article quality predictions' + '.xlsx')\n",
    "results_and_details.to_excel(output_excel_path_3, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>regional_division</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>title</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>1171163550</td>\n",
       "      <td>C</td>\n",
       "      <td>0.597920</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>1177621427</td>\n",
       "      <td>C</td>\n",
       "      <td>0.377070</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>1168359898</td>\n",
       "      <td>C</td>\n",
       "      <td>0.324460</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>1165909508</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>Good article (sometimes called A-class)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>1179139816</td>\n",
       "      <td>C</td>\n",
       "      <td>0.646384</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Albertville, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Albertville, Alabama</td>\n",
       "      <td>1179198677</td>\n",
       "      <td>C</td>\n",
       "      <td>0.575156</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alexander City, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Alexander City, Alabama</td>\n",
       "      <td>1179140073</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.389467</td>\n",
       "      <td>Good article (sometimes called A-class)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Aliceville, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Aliceville, Alabama</td>\n",
       "      <td>1167792390</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.563505</td>\n",
       "      <td>Good article (sometimes called A-class)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Allgood, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Allgood, Alabama</td>\n",
       "      <td>1165909718</td>\n",
       "      <td>C</td>\n",
       "      <td>0.417820</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Altoona, Alabama</td>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>5074296</td>\n",
       "      <td>Altoona, Alabama</td>\n",
       "      <td>1165909823</td>\n",
       "      <td>C</td>\n",
       "      <td>0.379118</td>\n",
       "      <td>C-class article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state               page_title            regional_division  \\\n",
       "0  Alabama       Abbeville, Alabama  South (East South Central)    \n",
       "1  Alabama      Adamsville, Alabama  South (East South Central)    \n",
       "2  Alabama         Addison, Alabama  South (East South Central)    \n",
       "3  Alabama           Akron, Alabama  South (East South Central)    \n",
       "4  Alabama       Alabaster, Alabama  South (East South Central)    \n",
       "5  Alabama     Albertville, Alabama  South (East South Central)    \n",
       "6  Alabama  Alexander City, Alabama  South (East South Central)    \n",
       "7  Alabama      Aliceville, Alabama  South (East South Central)    \n",
       "8  Alabama         Allgood, Alabama  South (East South Central)    \n",
       "9  Alabama         Altoona, Alabama  South (East South Central)    \n",
       "\n",
       "   Population Est. 2022                    title   lastrevid prediction  \\\n",
       "0               5074296       Abbeville, Alabama  1171163550          C   \n",
       "1               5074296      Adamsville, Alabama  1177621427          C   \n",
       "2               5074296         Addison, Alabama  1168359898          C   \n",
       "3               5074296           Akron, Alabama  1165909508         GA   \n",
       "4               5074296       Alabaster, Alabama  1179139816          C   \n",
       "5               5074296     Albertville, Alabama  1179198677          C   \n",
       "6               5074296  Alexander City, Alabama  1179140073         GA   \n",
       "7               5074296      Aliceville, Alabama  1167792390         GA   \n",
       "8               5074296         Allgood, Alabama  1165909718          C   \n",
       "9               5074296         Altoona, Alabama  1165909823          C   \n",
       "\n",
       "   probability                          prediction_text  \n",
       "0     0.597920                          C-class article  \n",
       "1     0.377070                          C-class article  \n",
       "2     0.324460                          C-class article  \n",
       "3     0.448584  Good article (sometimes called A-class)  \n",
       "4     0.646384                          C-class article  \n",
       "5     0.575156                          C-class article  \n",
       "6     0.389467  Good article (sometimes called A-class)  \n",
       "7     0.563505  Good article (sometimes called A-class)  \n",
       "8     0.417820                          C-class article  \n",
       "9     0.379118                          C-class article  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_and_details['lastrevid'] = results_and_details['lastrevid'].astype(str)\n",
    "results_and_details['lastrevid'] = results_and_details['lastrevid'].str.split('.').str[0]\n",
    "\n",
    "\n",
    "results_and_details.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "This segment consists of the updates to the dataframes to get the details of the pages at a state and division level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by State:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5074296</td>\n",
       "      <td>461</td>\n",
       "      <td>14</td>\n",
       "      <td>616</td>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>182</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>733583</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7359197</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3045637</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>39029342</td>\n",
       "      <td>482</td>\n",
       "      <td>102</td>\n",
       "      <td>207</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  Population Est. 2022  title    B    C  FA   GA  Start  Stub  \\\n",
       "0     Alabama               5074296    461   14  616   4  102    182     4   \n",
       "1      Alaska                733583    149    8   89   1   30     19     2   \n",
       "2     Arizona               7359197     91   12   54   1   23      0     1   \n",
       "3    Arkansas               3045637    500    3  322   0   72    102     1   \n",
       "4  California              39029342    482  102  207   3  170      0     0   \n",
       "\n",
       "   total articles per capita  High Quality (FA or GA) articles per capita  \n",
       "0                   0.000091                                     0.000021  \n",
       "1                   0.000203                                     0.000042  \n",
       "2                   0.000012                                     0.000003  \n",
       "3                   0.000164                                     0.000024  \n",
       "4                   0.000012                                     0.000004  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a copy of the results to get details by state\n",
    "results_and_details_state = results_and_details.copy()\n",
    "\n",
    "# Group the data to get the population and number of articles by state\n",
    "results_and_details_state_groups = results_and_details_state.groupby('state').agg({'Population Est. 2022': 'max', 'title': 'nunique'}).reset_index()\n",
    "\n",
    "# Pivot the data to get the number of articles by quality\n",
    "results_and_details_state_groups_pivot = results_and_details_state.pivot_table(index='state', columns='prediction', values='title', aggfunc='count', fill_value=0).reset_index()\n",
    "\n",
    "#results_and_details_state_groups.head(10)\n",
    "#results_and_details_state_groups_pivot.head(10)\n",
    "\n",
    "# Merge the above 2 to get the combined dataframe\n",
    "results_and_details_state_aggregate = results_and_details_state_groups.merge(results_and_details_state_groups_pivot, on='state', how='left')\n",
    "#results_and_details_state_aggregate.head(5)\n",
    "\n",
    "# Add columns for articles per capita\n",
    "results_and_details_state_aggregate['total articles per capita'] = results_and_details_state_aggregate['title']/results_and_details_state_aggregate['Population Est. 2022']\n",
    "results_and_details_state_aggregate['High Quality (FA or GA) articles per capita'] = (results_and_details_state_aggregate['FA'] + results_and_details_state_aggregate['GA'])/results_and_details_state_aggregate['Population Est. 2022']\n",
    "\n",
    "results_and_details_state_aggregate.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by Region and Division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midwest (East North Central)</td>\n",
       "      <td>47097779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midwest (West North Central)</td>\n",
       "      <td>19721893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Northeast (Middle Atlantic)</td>\n",
       "      <td>41910858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northeast (New England)</td>\n",
       "      <td>11503343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>19578002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South (South Atlantic)</td>\n",
       "      <td>66781137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South (West South Central)</td>\n",
       "      <td>41685250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West (Mountain)</td>\n",
       "      <td>25514320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West (Pacific)</td>\n",
       "      <td>53229044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               regional_division  Population Est. 2022\n",
       "0  Midwest (East North Central)               47097779\n",
       "1  Midwest (West North Central)               19721893\n",
       "2   Northeast (Middle Atlantic)               41910858\n",
       "3       Northeast (New England)               11503343\n",
       "4    South (East South Central)               19578002\n",
       "5        South (South Atlantic)               66781137\n",
       "6    South (West South Central)               41685250\n",
       "7               West (Mountain)               25514320\n",
       "8                West (Pacific)               53229044"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the population totals by regional division\n",
    "results_and_details_reg_1 = results_and_details_state.groupby(['state','regional_division']).agg({'Population Est. 2022': 'max'}).reset_index()\n",
    "results_and_details_reg_1.sort_values(by='regional_division', ascending=True).head(50)\n",
    "\n",
    "population_by_region = results_and_details_reg_1.groupby('regional_division').agg({'Population Est. 2022': 'sum'}).reset_index()\n",
    "population_by_region.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midwest (East North Central)</td>\n",
       "      <td>4753</td>\n",
       "      <td>138</td>\n",
       "      <td>2976</td>\n",
       "      <td>7</td>\n",
       "      <td>712</td>\n",
       "      <td>862</td>\n",
       "      <td>59</td>\n",
       "      <td>47097779</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midwest (West North Central)</td>\n",
       "      <td>3578</td>\n",
       "      <td>40</td>\n",
       "      <td>2727</td>\n",
       "      <td>5</td>\n",
       "      <td>635</td>\n",
       "      <td>161</td>\n",
       "      <td>10</td>\n",
       "      <td>19721893</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Northeast (Middle Atlantic)</td>\n",
       "      <td>3781</td>\n",
       "      <td>283</td>\n",
       "      <td>1747</td>\n",
       "      <td>142</td>\n",
       "      <td>914</td>\n",
       "      <td>234</td>\n",
       "      <td>470</td>\n",
       "      <td>41910858</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northeast (New England)</td>\n",
       "      <td>1437</td>\n",
       "      <td>56</td>\n",
       "      <td>920</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>171</td>\n",
       "      <td>65</td>\n",
       "      <td>11503343</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>1529</td>\n",
       "      <td>40</td>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>311</td>\n",
       "      <td>9</td>\n",
       "      <td>19578002</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South (South Atlantic)</td>\n",
       "      <td>1850</td>\n",
       "      <td>112</td>\n",
       "      <td>1204</td>\n",
       "      <td>13</td>\n",
       "      <td>533</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>66781137</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South (West South Central)</td>\n",
       "      <td>2103</td>\n",
       "      <td>62</td>\n",
       "      <td>1189</td>\n",
       "      <td>10</td>\n",
       "      <td>625</td>\n",
       "      <td>213</td>\n",
       "      <td>7</td>\n",
       "      <td>41685250</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West (Mountain)</td>\n",
       "      <td>1189</td>\n",
       "      <td>49</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>338</td>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>25514320</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West (Pacific)</td>\n",
       "      <td>1304</td>\n",
       "      <td>133</td>\n",
       "      <td>595</td>\n",
       "      <td>19</td>\n",
       "      <td>471</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>53229044</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               regional_division  title    B     C   FA   GA  Start  Stub  \\\n",
       "0  Midwest (East North Central)    4753  138  2976    7  712    862    59   \n",
       "1  Midwest (West North Central)    3578   40  2727    5  635    161    10   \n",
       "2   Northeast (Middle Atlantic)    3781  283  1747  142  914    234   470   \n",
       "3       Northeast (New England)    1437   56   920    9  216    171    65   \n",
       "4    South (East South Central)    1529   40  1261    6  365    311     9   \n",
       "5        South (South Atlantic)    1850  112  1204   13  533    117     5   \n",
       "6    South (West South Central)    2103   62  1189   10  625    213     7   \n",
       "7               West (Mountain)    1189   49   722    4  338     89     9   \n",
       "8                West (Pacific)    1304  133   595   19  471     40    46   \n",
       "\n",
       "   Population Est. 2022  total articles per capita  \\\n",
       "0              47097779                   0.000101   \n",
       "1              19721893                   0.000181   \n",
       "2              41910858                   0.000090   \n",
       "3              11503343                   0.000125   \n",
       "4              19578002                   0.000078   \n",
       "5              66781137                   0.000028   \n",
       "6              41685250                   0.000050   \n",
       "7              25514320                   0.000047   \n",
       "8              53229044                   0.000024   \n",
       "\n",
       "   High Quality (FA or GA) articles per capita  \n",
       "0                                     0.000015  \n",
       "1                                     0.000032  \n",
       "2                                     0.000025  \n",
       "3                                     0.000020  \n",
       "4                                     0.000019  \n",
       "5                                     0.000008  \n",
       "6                                     0.000015  \n",
       "7                                     0.000013  \n",
       "8                                     0.000009  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a copy of the results to get details by state\n",
    "results_and_details_region = results_and_details.copy()\n",
    "\n",
    "# Group the data to get the population and number of articles by state\n",
    "results_and_details_region_groups = results_and_details_region.groupby('regional_division').agg({'title': 'nunique'}).reset_index()\n",
    "\n",
    "# Pivot the data to get the number of articles by quality\n",
    "results_and_details_region_groups_pivot = results_and_details_region.pivot_table(index='regional_division', columns='prediction', values='title', aggfunc='count', fill_value=0).reset_index()\n",
    "\n",
    "#results_and_details_region_groups.head(10)\n",
    "#results_and_details_region_groups_pivot.head(10)\n",
    "\n",
    "# Merge the above 2 to get the combined dataframe\n",
    "results_and_details_region_aggregate = results_and_details_region_groups.merge(results_and_details_region_groups_pivot, on='regional_division', how='left')\n",
    "#results_and_details_region_aggregate.head(10)\n",
    "\n",
    "# Get the population by region\n",
    "results_and_details_region_aggregate = results_and_details_region_aggregate.merge(population_by_region, on='regional_division', how='left')\n",
    "\n",
    "# Add columns for articles per capita\n",
    "results_and_details_region_aggregate['total articles per capita'] = results_and_details_region_aggregate['title']/results_and_details_region_aggregate['Population Est. 2022']\n",
    "results_and_details_region_aggregate['High Quality (FA or GA) articles per capita'] = (results_and_details_region_aggregate['FA'] + results_and_details_region_aggregate['GA'])/results_and_details_region_aggregate['Population Est. 2022']\n",
    "\n",
    "results_and_details_region_aggregate.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Top 10 US states by coverage: The 10 US states with the highest total articles per capita (in descending order) .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>647064</td>\n",
       "      <td>329</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>779261</td>\n",
       "      <td>356</td>\n",
       "      <td>5</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maine</td>\n",
       "      <td>1385340</td>\n",
       "      <td>483</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>909824</td>\n",
       "      <td>311</td>\n",
       "      <td>2</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>3200517</td>\n",
       "      <td>1043</td>\n",
       "      <td>8</td>\n",
       "      <td>903</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>733583</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>12972008</td>\n",
       "      <td>2556</td>\n",
       "      <td>60</td>\n",
       "      <td>1347</td>\n",
       "      <td>3</td>\n",
       "      <td>563</td>\n",
       "      <td>140</td>\n",
       "      <td>443</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>10034113</td>\n",
       "      <td>1773</td>\n",
       "      <td>49</td>\n",
       "      <td>861</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>685</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>581381</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1395231</td>\n",
       "      <td>234</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  Population Est. 2022  title   B     C  FA   GA  Start  \\\n",
       "42        Vermont                647064    329   3   185   0   45     35   \n",
       "31   North Dakota                779261    356   5   309   0   26     16   \n",
       "17          Maine               1385340    483   2   300   0   43    135   \n",
       "38   South Dakota                909824    311   2   248   0   56      3   \n",
       "13           Iowa               3200517   1043   8   903   2  102     27   \n",
       "1          Alaska                733583    149   8    89   1   30     19   \n",
       "35   Pennsylvania              12972008   2556  60  1347   3  563    140   \n",
       "20       Michigan              10034113   1773  49   861   1  132    685   \n",
       "47        Wyoming                581381     99   1    55   0   39      3   \n",
       "26  New Hampshire               1395231    234   4   167   1   62      0   \n",
       "\n",
       "    Stub  total articles per capita  \\\n",
       "42    61                   0.000508   \n",
       "31     0                   0.000457   \n",
       "17     3                   0.000349   \n",
       "38     2                   0.000342   \n",
       "13     1                   0.000326   \n",
       "1      2                   0.000203   \n",
       "35   443                   0.000197   \n",
       "20    45                   0.000177   \n",
       "47     1                   0.000170   \n",
       "26     0                   0.000168   \n",
       "\n",
       "    High Quality (FA or GA) articles per capita  \n",
       "42                                     0.000070  \n",
       "31                                     0.000033  \n",
       "17                                     0.000031  \n",
       "38                                     0.000062  \n",
       "13                                     0.000032  \n",
       "1                                      0.000042  \n",
       "35                                     0.000044  \n",
       "20                                     0.000013  \n",
       "47                                     0.000067  \n",
       "26                                     0.000045  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_states_by_coverage = results_and_details_state_aggregate.sort_values(by='total articles per capita', ascending=False)\n",
    "top10_states_by_coverage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Bottom 10 US states by coverage: The 10 US states with the lowest total articles per capita (in ascending order) .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>10698973</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>3177772</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>39029342</td>\n",
       "      <td>482</td>\n",
       "      <td>102</td>\n",
       "      <td>207</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7359197</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>8683619</td>\n",
       "      <td>133</td>\n",
       "      <td>44</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>22244823</td>\n",
       "      <td>412</td>\n",
       "      <td>34</td>\n",
       "      <td>235</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>4019800</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>2937150</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>6164660</td>\n",
       "      <td>157</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>5892539</td>\n",
       "      <td>192</td>\n",
       "      <td>14</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  Population Est. 2022  title    B    C  FA   GA  Start  \\\n",
       "30  North Carolina              10698973     50    2   27   1   20      0   \n",
       "25          Nevada               3177772     19    1   10   0    8      0   \n",
       "4       California              39029342    482  102  207   3  170      0   \n",
       "2          Arizona               7359197     91   12   54   1   23      0   \n",
       "43        Virginia               8683619    133   44  186   2   34      0   \n",
       "7          Florida              22244823    412   34  235   6  114     23   \n",
       "33        Oklahoma               4019800     75    8   35   0   31      1   \n",
       "14          Kansas               2937150     63   11   30   1   21      0   \n",
       "18        Maryland               6164660    157    8  100   2   40      4   \n",
       "46       Wisconsin               5892539    192   14  117   0   61      1   \n",
       "\n",
       "    Stub  total articles per capita  \\\n",
       "30     0                   0.000005   \n",
       "25     0                   0.000006   \n",
       "4      0                   0.000012   \n",
       "2      1                   0.000012   \n",
       "43     0                   0.000015   \n",
       "7      1                   0.000019   \n",
       "33     0                   0.000019   \n",
       "14     0                   0.000021   \n",
       "18     3                   0.000025   \n",
       "46     0                   0.000033   \n",
       "\n",
       "    High Quality (FA or GA) articles per capita  \n",
       "30                                     0.000002  \n",
       "25                                     0.000003  \n",
       "4                                      0.000004  \n",
       "2                                      0.000003  \n",
       "43                                     0.000004  \n",
       "7                                      0.000005  \n",
       "33                                     0.000008  \n",
       "14                                     0.000007  \n",
       "18                                     0.000007  \n",
       "46                                     0.000010  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom10_states_by_coverage = results_and_details_state_aggregate.sort_values(by='total articles per capita', ascending=True)\n",
    "bottom10_states_by_coverage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Top 10 US states by high quality: The 10 US states with the highest high quality articles per capita (in descending order) .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>647064</td>\n",
       "      <td>329</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>581381</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>909824</td>\n",
       "      <td>311</td>\n",
       "      <td>2</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1775156</td>\n",
       "      <td>232</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1122867</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1395231</td>\n",
       "      <td>234</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>12972008</td>\n",
       "      <td>2556</td>\n",
       "      <td>60</td>\n",
       "      <td>1347</td>\n",
       "      <td>3</td>\n",
       "      <td>563</td>\n",
       "      <td>140</td>\n",
       "      <td>443</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>6177957</td>\n",
       "      <td>951</td>\n",
       "      <td>6</td>\n",
       "      <td>605</td>\n",
       "      <td>1</td>\n",
       "      <td>262</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>733583</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>9261699</td>\n",
       "      <td>564</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  Population Est. 2022  title    B     C   FA   GA  Start  \\\n",
       "42        Vermont                647064    329    3   185    0   45     35   \n",
       "47        Wyoming                581381     99    1    55    0   39      3   \n",
       "38   South Dakota                909824    311    2   248    0   56      3   \n",
       "45  West Virginia               1775156    232    6   120    0  106      0   \n",
       "24        Montana               1122867    128    8    62    0   55      3   \n",
       "26  New Hampshire               1395231    234    4   167    1   62      0   \n",
       "35   Pennsylvania              12972008   2556   60  1347    3  563    140   \n",
       "23       Missouri               6177957    951    6   605    1  262     71   \n",
       "1          Alaska                733583    149    8    89    1   30     19   \n",
       "27     New Jersey               9261699    564  183     0  130  249      0   \n",
       "\n",
       "    Stub  total articles per capita  \\\n",
       "42    61                   0.000508   \n",
       "47     1                   0.000170   \n",
       "38     2                   0.000342   \n",
       "45     0                   0.000131   \n",
       "24     0                   0.000114   \n",
       "26     0                   0.000168   \n",
       "35   443                   0.000197   \n",
       "23     6                   0.000154   \n",
       "1      2                   0.000203   \n",
       "27     2                   0.000061   \n",
       "\n",
       "    High Quality (FA or GA) articles per capita  \n",
       "42                                     0.000070  \n",
       "47                                     0.000067  \n",
       "38                                     0.000062  \n",
       "45                                     0.000060  \n",
       "24                                     0.000049  \n",
       "26                                     0.000045  \n",
       "35                                     0.000044  \n",
       "23                                     0.000043  \n",
       "1                                      0.000042  \n",
       "27                                     0.000041  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_states_by_HQ_coverage = results_and_details_state_aggregate.sort_values(by='High Quality (FA or GA) articles per capita', ascending=False)\n",
    "top10_states_by_HQ_coverage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Bottom 10 US states by high quality: The 10 US states with the lowest high quality articles per capita (in ascending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>10698973</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>3177772</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7359197</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>8683619</td>\n",
       "      <td>133</td>\n",
       "      <td>44</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>39029342</td>\n",
       "      <td>482</td>\n",
       "      <td>102</td>\n",
       "      <td>207</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>22244823</td>\n",
       "      <td>412</td>\n",
       "      <td>34</td>\n",
       "      <td>235</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York</td>\n",
       "      <td>19677151</td>\n",
       "      <td>661</td>\n",
       "      <td>40</td>\n",
       "      <td>400</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>94</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>6164660</td>\n",
       "      <td>157</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>2937150</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>4019800</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  Population Est. 2022  title    B    C  FA   GA  Start  \\\n",
       "30  North Carolina              10698973     50    2   27   1   20      0   \n",
       "25          Nevada               3177772     19    1   10   0    8      0   \n",
       "2          Arizona               7359197     91   12   54   1   23      0   \n",
       "43        Virginia               8683619    133   44  186   2   34      0   \n",
       "4       California              39029342    482  102  207   3  170      0   \n",
       "7          Florida              22244823    412   34  235   6  114     23   \n",
       "29        New York              19677151    661   40  400   9  102     94   \n",
       "18        Maryland               6164660    157    8  100   2   40      4   \n",
       "14          Kansas               2937150     63   11   30   1   21      0   \n",
       "33        Oklahoma               4019800     75    8   35   0   31      1   \n",
       "\n",
       "    Stub  total articles per capita  \\\n",
       "30     0                   0.000005   \n",
       "25     0                   0.000006   \n",
       "2      1                   0.000012   \n",
       "43     0                   0.000015   \n",
       "4      0                   0.000012   \n",
       "7      1                   0.000019   \n",
       "29    25                   0.000034   \n",
       "18     3                   0.000025   \n",
       "14     0                   0.000021   \n",
       "33     0                   0.000019   \n",
       "\n",
       "    High Quality (FA or GA) articles per capita  \n",
       "30                                     0.000002  \n",
       "25                                     0.000003  \n",
       "2                                      0.000003  \n",
       "43                                     0.000004  \n",
       "4                                      0.000004  \n",
       "7                                      0.000005  \n",
       "29                                     0.000006  \n",
       "18                                     0.000007  \n",
       "14                                     0.000007  \n",
       "33                                     0.000008  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom10_states_by_HQ_coverage = results_and_details_state_aggregate.sort_values(by='High Quality (FA or GA) articles per capita', ascending=True)\n",
    "bottom10_states_by_HQ_coverage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Census divisions by total coverage: A rank ordered list of US census divisions (in descending order) by total articles per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midwest (West North Central)</td>\n",
       "      <td>3578</td>\n",
       "      <td>40</td>\n",
       "      <td>2727</td>\n",
       "      <td>5</td>\n",
       "      <td>635</td>\n",
       "      <td>161</td>\n",
       "      <td>10</td>\n",
       "      <td>19721893</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northeast (New England)</td>\n",
       "      <td>1437</td>\n",
       "      <td>56</td>\n",
       "      <td>920</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>171</td>\n",
       "      <td>65</td>\n",
       "      <td>11503343</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midwest (East North Central)</td>\n",
       "      <td>4753</td>\n",
       "      <td>138</td>\n",
       "      <td>2976</td>\n",
       "      <td>7</td>\n",
       "      <td>712</td>\n",
       "      <td>862</td>\n",
       "      <td>59</td>\n",
       "      <td>47097779</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Northeast (Middle Atlantic)</td>\n",
       "      <td>3781</td>\n",
       "      <td>283</td>\n",
       "      <td>1747</td>\n",
       "      <td>142</td>\n",
       "      <td>914</td>\n",
       "      <td>234</td>\n",
       "      <td>470</td>\n",
       "      <td>41910858</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>1529</td>\n",
       "      <td>40</td>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>311</td>\n",
       "      <td>9</td>\n",
       "      <td>19578002</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South (West South Central)</td>\n",
       "      <td>2103</td>\n",
       "      <td>62</td>\n",
       "      <td>1189</td>\n",
       "      <td>10</td>\n",
       "      <td>625</td>\n",
       "      <td>213</td>\n",
       "      <td>7</td>\n",
       "      <td>41685250</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West (Mountain)</td>\n",
       "      <td>1189</td>\n",
       "      <td>49</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>338</td>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>25514320</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South (South Atlantic)</td>\n",
       "      <td>1850</td>\n",
       "      <td>112</td>\n",
       "      <td>1204</td>\n",
       "      <td>13</td>\n",
       "      <td>533</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>66781137</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West (Pacific)</td>\n",
       "      <td>1304</td>\n",
       "      <td>133</td>\n",
       "      <td>595</td>\n",
       "      <td>19</td>\n",
       "      <td>471</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>53229044</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               regional_division  title    B     C   FA   GA  Start  Stub  \\\n",
       "1  Midwest (West North Central)    3578   40  2727    5  635    161    10   \n",
       "3       Northeast (New England)    1437   56   920    9  216    171    65   \n",
       "0  Midwest (East North Central)    4753  138  2976    7  712    862    59   \n",
       "2   Northeast (Middle Atlantic)    3781  283  1747  142  914    234   470   \n",
       "4    South (East South Central)    1529   40  1261    6  365    311     9   \n",
       "6    South (West South Central)    2103   62  1189   10  625    213     7   \n",
       "7               West (Mountain)    1189   49   722    4  338     89     9   \n",
       "5        South (South Atlantic)    1850  112  1204   13  533    117     5   \n",
       "8                West (Pacific)    1304  133   595   19  471     40    46   \n",
       "\n",
       "   Population Est. 2022  total articles per capita  \\\n",
       "1              19721893                   0.000181   \n",
       "3              11503343                   0.000125   \n",
       "0              47097779                   0.000101   \n",
       "2              41910858                   0.000090   \n",
       "4              19578002                   0.000078   \n",
       "6              41685250                   0.000050   \n",
       "7              25514320                   0.000047   \n",
       "5              66781137                   0.000028   \n",
       "8              53229044                   0.000024   \n",
       "\n",
       "   High Quality (FA or GA) articles per capita  \n",
       "1                                     0.000032  \n",
       "3                                     0.000020  \n",
       "0                                     0.000015  \n",
       "2                                     0.000025  \n",
       "4                                     0.000019  \n",
       "6                                     0.000015  \n",
       "7                                     0.000013  \n",
       "5                                     0.000008  \n",
       "8                                     0.000009  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "top_divisions_by_HQ_coverage = results_and_details_region_aggregate.sort_values(by='total articles per capita', ascending=False)\n",
    "top_divisions_by_HQ_coverage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Census divisions by high quality coverage: Rank ordered list of US census divisions (in descending order) by high quality articles per capita.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>title</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>FA</th>\n",
       "      <th>GA</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stub</th>\n",
       "      <th>Population Est. 2022</th>\n",
       "      <th>total articles per capita</th>\n",
       "      <th>High Quality (FA or GA) articles per capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midwest (West North Central)</td>\n",
       "      <td>3578</td>\n",
       "      <td>40</td>\n",
       "      <td>2727</td>\n",
       "      <td>5</td>\n",
       "      <td>635</td>\n",
       "      <td>161</td>\n",
       "      <td>10</td>\n",
       "      <td>19721893</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Northeast (Middle Atlantic)</td>\n",
       "      <td>3781</td>\n",
       "      <td>283</td>\n",
       "      <td>1747</td>\n",
       "      <td>142</td>\n",
       "      <td>914</td>\n",
       "      <td>234</td>\n",
       "      <td>470</td>\n",
       "      <td>41910858</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northeast (New England)</td>\n",
       "      <td>1437</td>\n",
       "      <td>56</td>\n",
       "      <td>920</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>171</td>\n",
       "      <td>65</td>\n",
       "      <td>11503343</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South (East South Central)</td>\n",
       "      <td>1529</td>\n",
       "      <td>40</td>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>311</td>\n",
       "      <td>9</td>\n",
       "      <td>19578002</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midwest (East North Central)</td>\n",
       "      <td>4753</td>\n",
       "      <td>138</td>\n",
       "      <td>2976</td>\n",
       "      <td>7</td>\n",
       "      <td>712</td>\n",
       "      <td>862</td>\n",
       "      <td>59</td>\n",
       "      <td>47097779</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South (West South Central)</td>\n",
       "      <td>2103</td>\n",
       "      <td>62</td>\n",
       "      <td>1189</td>\n",
       "      <td>10</td>\n",
       "      <td>625</td>\n",
       "      <td>213</td>\n",
       "      <td>7</td>\n",
       "      <td>41685250</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West (Mountain)</td>\n",
       "      <td>1189</td>\n",
       "      <td>49</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>338</td>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>25514320</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West (Pacific)</td>\n",
       "      <td>1304</td>\n",
       "      <td>133</td>\n",
       "      <td>595</td>\n",
       "      <td>19</td>\n",
       "      <td>471</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>53229044</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South (South Atlantic)</td>\n",
       "      <td>1850</td>\n",
       "      <td>112</td>\n",
       "      <td>1204</td>\n",
       "      <td>13</td>\n",
       "      <td>533</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>66781137</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               regional_division  title    B     C   FA   GA  Start  Stub  \\\n",
       "1  Midwest (West North Central)    3578   40  2727    5  635    161    10   \n",
       "2   Northeast (Middle Atlantic)    3781  283  1747  142  914    234   470   \n",
       "3       Northeast (New England)    1437   56   920    9  216    171    65   \n",
       "4    South (East South Central)    1529   40  1261    6  365    311     9   \n",
       "0  Midwest (East North Central)    4753  138  2976    7  712    862    59   \n",
       "6    South (West South Central)    2103   62  1189   10  625    213     7   \n",
       "7               West (Mountain)    1189   49   722    4  338     89     9   \n",
       "8                West (Pacific)    1304  133   595   19  471     40    46   \n",
       "5        South (South Atlantic)    1850  112  1204   13  533    117     5   \n",
       "\n",
       "   Population Est. 2022  total articles per capita  \\\n",
       "1              19721893                   0.000181   \n",
       "2              41910858                   0.000090   \n",
       "3              11503343                   0.000125   \n",
       "4              19578002                   0.000078   \n",
       "0              47097779                   0.000101   \n",
       "6              41685250                   0.000050   \n",
       "7              25514320                   0.000047   \n",
       "8              53229044                   0.000024   \n",
       "5              66781137                   0.000028   \n",
       "\n",
       "   High Quality (FA or GA) articles per capita  \n",
       "1                                     0.000032  \n",
       "2                                     0.000025  \n",
       "3                                     0.000020  \n",
       "4                                     0.000019  \n",
       "0                                     0.000015  \n",
       "6                                     0.000015  \n",
       "7                                     0.000013  \n",
       "8                                     0.000009  \n",
       "5                                     0.000008  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "top_divisions_by_HQ_coverage = results_and_details_region_aggregate.sort_values(by='High Quality (FA or GA) articles per capita', ascending=False)\n",
    "top_divisions_by_HQ_coverage.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
